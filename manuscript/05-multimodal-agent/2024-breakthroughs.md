---
chapter_number: 6
title: "多模态与Agent：2024年的能力跃升"
title_en: "Multimodal and Agent Capabilities: 2024 Breakthroughs"
period: "2024"
status: draft
word_count: 11800
key_events:
  - deepseek-v2-2024
  - gemini-15-release-2024
  - sora-release-2024
  - claude-3-release-2024
  - nvidia-gtc-2024
  - qwen-15-release-2024
  - gpt4o-release-2024
  - llama-31-release-2024
  - glm-4-release-2024
  - o1-release-2024
key_organizations:
  - openai
  - google
  - anthropic
  - meta
  - deepseek
  - alibaba
  - zhipu
  - nvidia
technical_concepts:
  - multimodal
  - native-multimodal
  - agent-capabilities
  - computer-use
  - moe-architecture
  - reasoning-models
  - long-context
anecdote_count: 2
created_date: 2025-10-17
last_updated: 2025-10-17
---

# Chapter 6: 多模态与Agent：2024年的能力跃升

## 引言 (Introduction)

2024年1月，全球AI竞赛进入新阶段。

2023年的"百模大战"证明了中美都能快速开发对话式大模型。但ChatGPT仍然局限在文本交互，距离真正的通用人工智能还有巨大距离。**下一个突破口在哪里？**

答案在2024年逐渐清晰：**多模态能力和Agent自主性**。

从文本到图像、视频、音频的统一处理；从被动回答到主动完成复杂任务；从单一模型到工具调用和环境交互——2024年，AI的能力边界被全方位拓展。

OpenAI的Sora让世界看到了视频生成的惊人潜力，GPT-4o实现了真正的原生多模态统一处理。Google的Gemini 1.5突破了上下文长度极限，达到前所未有的1M tokens。Anthropic的Claude 3首次在综合能力上全面超越GPT-4，并引入革命性的"Computer Use"功能。Meta的Llama 3.1 405B证明开源模型可以达到闭源水平。

中国同样在快速追赶。DeepSeek的MoE架构创新引领全球，阿里Qwen系列在开源生态上建立领导地位，智谱GLM-4在中文场景持续深耕。

2024年，AI从"对话工具"进化为"多模态智能体"。本章将深入这一年的技术突破、战略转折和中美并驾齐驱的竞争格局。

## 中国创新：DeepSeek的MoE革命

### 从追随者到技术引领者

2024年1月，一家成立不到两年的中国AI创业公司震惊了全球：**DeepSeek**。

DeepSeek由前高频交易量化团队创立，低调但技术实力雄厚。当OpenAI、Google、Anthropic在参数规模上竞赛时，DeepSeek选择了一条不同的道路：**Mixture of Experts (MoE)架构的极致优化**。

### DeepSeek-V2：效率的胜利

**2024年1月**，DeepSeek发布V2模型。技术规格让人眼前一亮：

**创新架构**：
- 总参数：236B（2360亿）
- 激活参数：仅21B（每次推理只激活21B参数）
- MoE架构：64个专家，每次激活8个
- 推理成本：仅为GPT-4的1/10

**技术突破**：
MoE（专家混合）架构并非新概念，但DeepSeek的创新在于：
1. **细粒度专家分配**：不同专家专注不同知识领域和技能
2. **高效路由机制**：智能选择最相关的专家组合
3. **训练稳定性**：解决了MoE训练中的负载均衡问题

**性能表现**：
尽管激活参数仅21B，DeepSeek-V2在多个基准测试中接近甚至超越GPT-3.5：
- MMLU：75.8%（GPT-3.5: 70%）
- HumanEval：60.6%（编程能力）
- 中文理解：超越GPT-3.5

**战略意义**：

这是中国AI创业公司首次在技术路线上引领全球。DeepSeek证明了：在算力受限（美国GPU禁令）的情况下，通过算法创新同样可以达到世界一流水平。

**开源策略**：
DeepSeek将V2完全开源，Apache 2.0许可。这不仅是技术自信的体现，更是对全球AI社区的贡献。

**影响**：
- 引发全球对MoE架构的重新关注
- Llama 3、Qwen等后续模型纷纷采用MoE
- 证明"中国创新"不仅是跟随，更是引领

## Google的技术反击：Gemini 1.5

### 长上下文的游戏规则改变

**2024年2月**，Google DeepMind发布Gemini 1.5 Pro，用一个数字震惊了整个行业：**1M tokens上下文窗口**。

**技术突破**：

在此之前，主流模型的上下文长度：
- GPT-4：8K/32K tokens
- Claude 2：100K tokens
- 最长也就十几万tokens

Gemini 1.5突然跃升到**100万tokens**——相当于：
- 约75万英文单词
- 整本《战争与和平》
- 1小时高清视频
- 11小时音频
- 完整的大型代码库

**Mixture of Experts架构**：
Gemini 1.5同样采用MoE架构（受DeepSeek启发？），实现了性能和效率的平衡：
- 更少的激活参数
- 更低的推理成本
- 更快的响应速度

**应用场景**：

1M上下文开启了全新应用可能：
- **法律**：分析整套法律文档和判例
- **学术**：理解完整论文及引用文献
- **代码**：审查整个软件项目
- **视频**：理解长视频的完整情节
- **财务**：分析公司多年财报趋势

**战略意义**：

这是Google对OpenAI的强力反击。Bard的失败之后，Google通过技术创新重新证明了自己的实力。长上下文成为Gemini的差异化竞争优势。

**竞争影响**：
- OpenAI压力骤增（GPT-4仅32K）
- Anthropic加速Claude 3开发
- 长上下文成为新的竞争维度

## OpenAI的视频震撼：Sora

### 从文本到视频的跨越

**2024年2月15日**，OpenAI发布了Sora——一个文本到视频生成模型。

Demo视频一经发布，全球震撼。

**技术能力**：

给Sora一段文字描述，它能生成：
- 最长60秒高质量视频
- 1080p分辨率
- 多角度、多镜头连贯切换
- 复杂物理世界建模

**示例**：
```
提示词："一个穿着羽绒服的时尚女性走在东京街头，霓虹灯闪烁，雨后湿润的街道反射灯光"

Sora生成：完整60秒视频，女性步态自然，霓虹灯真实闪烁，水面反射准确，镜头跟随流畅，构图专业。
```

**技术洞察**：

Sora不仅是视频生成工具，更是**世界模型**（World Model）的探索：
- 理解物理规律（重力、光影、运动）
- 理解空间关系（景深、遮挡、视角）
- 理解时间连贯性（动作连续、因果关系）

这让人看到通往AGI的可能路径：AI需要理解真实世界的物理规律，而不仅仅是语言统计。

**行业冲击**：

**影视行业**震动：
- 传统视频制作成本高昂（数万到数十万美元/分钟）
- Sora生成成本几乎为零
- 创意门槛大幅降低

**广告营销**兴奋：
- 快速原型制作
- A/B测试不同创意
- 个性化内容生成

**艺术家们**矛盾：
- 工具的革命性进步
- 创作权和版权担忧
- 人类创意价值的重新定义

**局限性**：
Sora并非完美，仍有明显问题：
- 物理规律偶尔出错（人物走路不自然、物体穿墙）
- 无法精确控制（难以生成完全符合要求的细节）
- 计算成本高昂（60秒视频需要数分钟到数小时生成）

但这些都是"1.0版本"的问题。Sora证明了文本到视频生成的可行性，剩下的只是工程优化。

## Anthropic的全面超越：Claude 3

### 首次挑战GPT-4的统治

**2024年3月4日**，Anthropic发布Claude 3系列，包括三个版本：

**Claude 3 Haiku**（最快）：
- 最快的推理速度
- 适合高频调用场景
- 成本最低

**Claude 3 Sonnet**（平衡）：
- 性能和成本的最佳平衡
- Claude.ai默认模型
- 最受欢迎版本

**Claude 3 Opus**（最强）：
- 旗舰模型
- **首次在多个benchmark上全面超越GPT-4**
- 业界顶尖性能

**性能对比**：

| Benchmark | Claude 3 Opus | GPT-4 | Gemini Ultra |
|-----------|---------------|-------|--------------|
| MMLU | **86.8%** | 86.5% | 83.7% |
| GPQA (PhD级) | **50.4%** | 35.7% | 44.3% |
| MATH | **60.1%** | 52.9% | 53.2% |
| HumanEval | 84.9% | **85.4%** | 74.4% |

**历史性突破**：

这是自GPT-4发布以来，首次有模型在综合能力上全面超越它。特别是在研究生级别推理（GPQA）和数学推理上，Claude 3 Opus的领先优势显著。

**多模态能力**：
- 原生支持图像理解
- 文档分析（PDF、图表、截图）
- 200K上下文窗口（远超GPT-4）

**战略定位**：

Anthropic的差异化策略奏效：
- 不追求最大参数规模
- 专注安全性和可靠性
- 企业市场优先

**市场反应**：
- Notion AI切换到Claude 3
- 多个企业客户从GPT-4迁移
- Anthropic估值飙升

### 2024年6月：Claude 3.5 Sonnet的进一步突破

**跳过Opus 3.5的策略调整**：

Anthropic做了一个不寻常的决定：跳过Claude 3.5 Opus（旗舰版），直接发布3.5 Sonnet（平衡版）。

原因很简单：**Sonnet 3.5已经超越了Opus 3的性能，且成本仅为1/5**。

**性能飞跃**：
- MMLU：88.3%
- HumanEval：**92.0%**（超越GPT-4o的90.2%）
- 编程能力业界第一

**Computer Use革命**：

Claude 3.5 Sonnet引入了划时代的功能：**Computer Use**（计算机使用）。

Claude可以：
- 控制鼠标和键盘
- 操作任何软件和工具
- 浏览网页、使用应用
- 执行复杂的多步骤任务

**示例**：
```
用户："帮我在Excel中分析这份销售数据，生成趋势图，然后写一封邮件总结给我的团队"

Claude 3.5 Sonnet:
1. 打开Excel文件
2. 运行数据分析
3. 生成图表
4. 打开邮件客户端
5. 撰写邮件并插入图表
6. 完成
```

这是**AI Agent**能力的重大突破——从"对话工具"到"自主助手"。

## 算力基石：Nvidia GTC 2024

### AI时代的"军火商"

**2024年3月**，Nvidia GTC 2024大会在硅谷举行。CEO黄仁勋发布了**Blackwell架构**——下一代AI训练芯片。

**B200 GPU规格**：
- AI性能：比H100提升**30倍**
- 专为Transformer优化的张量核心
- 更高的显存带宽
- 更低的能耗比

**战略意义**：

Nvidia是整个AI竞赛的隐形主宰者。无论OpenAI、Google、Microsoft还是中国公司，**所有大模型训练都依赖Nvidia GPU**。

**数字证明**：
- GPT-3训练：约1万个V100 GPU
- GPT-4训练：估计2-3万个A100/H100 GPU
- 未来GPT-5：可能需要5-10万个B200 GPU

**中美竞争的关键变量**：

2022年10月，美国对华实施**GPU出口管制**，禁止向中国出口A100、H100等高性能AI芯片。

影响深远：
- 中国公司训练大模型算力受限
- 华为昇腾、寒武纪等国产芯片加速发展
- DeepSeek等公司专注算法效率优化
- 算力成为中美AI竞赛的战略瓶颈

**Nvidia的两难**：
- 中国是巨大市场（占Nvidia数据中心收入20-25%）
- 美国政府限制出口
- Nvidia试图推出"降级版"芯片（如A800、H800）
- 但2023年10月美国进一步收紧管制

黄仁勋成为AI时代最重要的人物之一——不是因为他开发AI模型，而是因为他提供训练AI的"铲子"。

## 开源标杆：阿里Qwen1.5与Meta Llama 3.1

### 中国开源力量的崛起

**2024年4月**，阿里巴巴发布**Qwen1.5**系列，继续其开源战略。

**技术规格**：
- 0.5B到72B，七个不同规模
- 32K上下文窗口
- 中英双语优化
- Apache 2.0许可（完全商业友好）

**性能表现**：
- MMLU：86.0%（Qwen1.5-72B）
- 中文理解：C-Eval 91.6%（远超GPT-4的86.8%）
- HumanEval：64.6%（编程能力）

**开源生态**：
到2024年4月，Qwen系列在HuggingFace上：
- 总下载量：500万+
- 全球第三（仅次于Meta Llama和Mistral）
- 中文开源模型第一名
- 衍生模型：数千个

**战略观察**：

阿里的开源策略与Meta高度相似，但有中国特色：
1. **云服务变现**：免费模型推广付费阿里云
2. **中文优势**：在中文场景建立不可替代性
3. **快速迭代**：每3-4个月一次重大更新
4. **生态建设**：成为中国开发者首选基础模型

### Meta的开源里程碑：Llama 3.1 405B

**2024年7月23日**，Meta发布**Llama 3.1**系列，包括一个重磅炸弹：**405B参数模型**。

**历史意义**：

这是**首个达到GPT-4性能水平的开源模型**。

**技术规格**：
- Llama 3.1 405B：4050亿参数
- 128K上下文窗口
- 多语言支持（8种语言）
- 原生支持function calling（工具调用）

**性能对比**：

| Benchmark | Llama 3.1 405B | GPT-4 | Claude 3 Opus |
|-----------|----------------|-------|---------------|
| MMLU | **86.0%** | 86.5% | 86.8% |
| HumanEval | **89%** | 85.4% | 84.9% |
| MATH | 73.8% | **52.9%** | 60.1% |

在编程和数学推理上，Llama 3.1甚至超越了闭源模型。

**开源vs闭源的转折点**：

Llama 3.1证明：**开源模型可以达到闭源水平**。

这改变了游戏规则：
- 为什么要付费API？自己部署Llama 3.1
- 为什么担心数据隐私？本地运行开源模型
- 为什么受限于API限制？开源模型完全可控

**全球影响**：
- 欧洲、东南亚、中东政府采用Llama 3.1构建本地化AI
- 创业公司基于Llama 3.1开发垂直应用
- 中国Qwen、GLM等受Llama架构启发

**Zuckerberg的胜利**：

Meta的开源战略取得战略性胜利。Llama生态规模已经可以与OpenAI竞争：
- 全球数百万开发者使用
- 数千个衍生模型和应用
- 成为开源AI的事实标准

## OpenAI的战略转折：GPT-4o免费开放

### 从封闭到开放的策略调整

**2024年5月13日**，OpenAI发布**GPT-4o**（"o" for "omni"，全方位）。

**技术突破**：

GPT-4o是**首个真正的原生多模态模型**：
- 文本、视觉、音频统一处理
- 不是拼接式多模态（如GPT-4 Vision），而是从训练开始就统一编码
- 实时语音对话能力
- 端到端延迟仅320毫秒（接近人类反应速度）

**性能提升**：
- 速度：比GPT-4快**2倍**
- 成本：降低**50%**
- 多语言：非英语性能大幅提升
- 视觉理解：超越GPT-4 Vision

**战略震撼：免费开放**

OpenAI做了一个惊人决定：**GPT-4o免费向所有用户开放**。

之前：
- GPT-3.5：免费
- GPT-4：付费（$20/月ChatGPT Plus）

现在：
- GPT-4o：**免费**（有限额度）
- GPT-4 Turbo：付费

**为什么免费？**

面对开源压力，OpenAI调整战略：
1. **规模效应**：免费吸引10亿+用户，建立不可替代性
2. **数据飞轮**：更多用户→更多反馈→更好模型
3. **生态锁定**：开发者基于GPT-4o开发应用，形成依赖
4. **高端变现**：企业客户、API、高级功能付费

**竞争影响**：

这对竞争对手是巨大压力：
- **Google**：Gemini免费版性能不如GPT-4o
- **Anthropic**：Claude企业客户为主，消费者市场被动
- **Meta**：开源模型虽免费，但用户体验不如GPT-4o
- **中国公司**：在国内市场面临巨大竞争

OpenAI的策略转变标志着AI竞赛进入新阶段：从"技术竞赛"到"生态竞赛"。

## 中国的持续追赶：智谱GLM-4

### 专注中文的深耕

**2024年8月**，智谱AI发布**GLM-4**系列，全面升级能力。

**技术特点**：
- GLM-4-9B：开源版本，高效推理
- GLM-4 Plus：闭源商业版，性能旗舰
- 中英双语，中文优化
- 128K上下文窗口

**性能表现**：
在中文benchmark上表现优异：
- C-Eval：89.5%
- CMMLU：88.2%
- 中文理解和生成能力接近GPT-4

**战略定位**：

智谱的策略是**"开源+闭源"双轨**：
- 开源GLM-4-9B吸引开发者
- 闭源GLM-4 Plus服务企业客户
- 两者相互促进，形成生态

**垂直应用**：
智谱专注垂直场景深度优化：
- 法律：ChatLaw法律咨询
- 医疗：智谱医疗对话
- 教育：智能教育助手
- 金融：财务分析工具

这些垂直应用在中文场景下往往超越通用模型。

## 推理革命：OpenAI o1系列

### 从快速反应到深度思考

**2024年9月12日**，OpenAI发布了一个全新类型的模型：**o1系列**。

这不是GPT-5，而是一个**推理模型**。

**核心创新**：

o1系列通过强化学习训练"思维链"（Chain of Thought）：
- 不是立即给出答案
- 而是先"思考"数秒到数分钟
- 展开内部推理过程
- 然后给出经过深度思考的答案

**两个版本**：
- **o1-preview**：完整推理能力，适合复杂问题
- **o1-mini**：轻量推理模型，速度更快，成本更低

**性能突破**：

在需要深度推理的任务上，o1远超GPT-4：

**数学推理**：
- AIME（美国数学邀请赛）：83.3%，达到前500名水平
- GPT-4：仅13.4%

**编程竞赛**：
- Codeforces：达到89th百分位
- GPT-4：仅11th百分位

**科学推理**：
- GPQA Diamond（PhD级科学问题）：78.0%
- GPT-4：56.1%

**范式转变**：

o1标志着从"**System 1**"（快速直觉）到"**System 2**"（慢速推理）的转变。

**System 1**（GPT-4）：
- 快速反应
- 依赖模式识别
- 类似人类直觉

**System 2**（o1）：
- 深度思考
- 逻辑推理
- 类似人类解题过程

**应用场景**：

o1不是替代GPT-4，而是互补：
- **GPT-4o**：日常对话、快速查询、内容生成
- **o1**：数学难题、科学研究、复杂编程、战略分析

**竞争影响**：

o1开辟了新的竞争维度——**推理能力**。这对竞争对手是新的挑战：
- Google、Anthropic需要开发类似能力
- 中国公司（字节豆包、DeepSeek）已经开始跟进
- 推理能力成为2024年下半年的新焦点

## 💡 轶事：Claude 3发布前夜的焦虑

2024年3月3日深夜，Anthropic总部。

Dario Amodei和团队正在准备第二天的Claude 3发布会。所有benchmark测试显示，Claude 3 Opus在多个任务上超越了GPT-4。但Dario仍然焦虑不安。

"如果OpenAI明天突然发布GPT-4.5怎么办？"他问团队。

这不是杞人忧天。OpenAI有过"狙击"竞争对手的记录：
- 2023年3月，Google发布Bard的前一天，OpenAI发布GPT-4
- 2023年11月，OpenAI DevDay前夕，突然宣布多项重大更新

但这次，团队决定赌一把。他们的信心来自三个月的严格测试和红队评估：Claude 3 Opus在推理深度和安全性上确实超越了GPT-4。

**3月4日上午9点**，Anthropic正式发布Claude 3。

**下午2点**，OpenAI没有任何反应。

**第二天**，科技媒体铺天盖地报道："Claude 3超越GPT-4"。

**一周后**，企业客户开始从GPT-4迁移到Claude 3。Notion、Quora等产品宣布切换到Claude。

Dario松了一口气。这场豪赌赢了。

但他知道，OpenAI不会坐视不管。两个月后，GPT-4o的发布证明了这一点。

这个故事揭示了AI竞赛的残酷现实：**技术领先只是暂时的，市场窗口稍纵即逝**。在这个行业，即使你今天领先，明天可能就被超越。唯一的办法是持续创新，永不停歇。

## 💡 轶事：Sora内测泄露风波

2024年2月，OpenAI Sora发布后，只有少数艺术家和影视工作者获得内测资格。

**11月26日**，一群获得Sora访问权限的艺术家集体"造反"，公开泄露了Sora的访问接口，允许任何人免费使用。

他们发布了一封公开信，抨击OpenAI：

> "我们不是免费劳动力。OpenAI利用我们的艺术作品和反馈来训练和宣传Sora，却只给我们有限的访问权限和模糊的承诺。这是对艺术家的剥削。"

**OpenAI的尴尬**：

OpenAI迅速关闭了泄露的接口，但这次事件揭示了一个深层矛盾：

**AI公司的视角**：
- 需要专家反馈改进产品
- 计算成本高昂，无法免费开放
- 内测是常规产品开发流程

**艺术家的视角**：
- AI用我们的作品训练（未经许可）
- 我们提供反馈却得不到补偿
- 内测是"免费劳动"

这不是简单的沟通问题，而是**AI时代创作价值和劳动价值的根本性分歧**。

**思考**：
- AI公司如何公平对待内测用户？
- 艺术家的贡献应该如何补偿？
- AI生成内容对人类创作者的影响如何平衡？

这些问题在2024年没有答案，但它们会持续困扰整个AI行业。

## 小结 (Summary)

2024年，AI的能力边界被全方位拓展。

从文本到多模态的转变标志着AI从"语言智能"走向"通用智能"。OpenAI的Sora展示了视频生成的惊人潜力，GPT-4o实现了文本、视觉、音频的原生统一处理。Google的Gemini 1.5通过1M tokens上下文突破了理解的长度极限。Anthropic的Claude 3首次在综合能力上全面超越GPT-4。

从被动助手到主动Agent的演进重新定义了AI的角色。Claude 3.5的Computer Use功能让AI可以操作任何软件，o1的推理能力让AI从"快速反应"进化到"深度思考"。AI不再只是回答问题的工具，而是能够自主完成复杂任务的智能体。

开源与闭源的边界在2024年进一步模糊。Meta的Llama 3.1 405B证明开源模型可以达到闭源水平，阿里的Qwen系列在中文场景建立领导地位。OpenAI的GPT-4o免费开放策略标志着竞争从技术转向生态。

中国在2024年展现出技术创新能力。DeepSeek的MoE架构优化引领全球，在算力受限的情况下通过算法创新实现世界一流性能。智谱、阿里、字节等公司在中文理解、垂直应用、快速迭代上形成独特优势。

中美在不同维度上的竞争格局逐渐清晰：美国在基础模型、多模态能力上保持领先；中国在算法效率、中文理解、垂直应用上建立优势。两国从"追赶-被追赶"走向"并驾齐驱"。

2024年也揭示了新的挑战。算力成为战略瓶颈，美国GPU禁令迫使中国走向自主创新。艺术家与AI公司的矛盾凸显创作价值的重新定义。推理能力的突破开辟了新的竞争维度。

在下一章中，我们将看到2024年下半年到2025年的演进：OpenAI o1如何引发推理竞赛，中国公司如何继续技术追赶，以及多模态和Agent能力如何进一步深化，最终推动整个行业奔向AGI目标。

从"对话工具"到"多模态智能体"——2024年，AI完成了关键的能力跃升，为通向AGI的道路铺平了基石。

---

**本章要点** (Key Takeaways):
- DeepSeek-V2通过MoE架构创新引领全球，证明中国在算力受限下仍能通过算法创新达到世界一流水平
- Gemini 1.5的1M tokens上下文突破开启长文档分析新时代，Google展现深厚技术实力
- Sora的视频生成能力揭示世界模型方向，标志AI从语言理解走向物理世界建模
- Claude 3首次全面超越GPT-4，Claude 3.5引入Computer Use功能开启AI Agent时代
- Llama 3.1 405B证明开源模型可达闭源水平，开源vs闭源竞争格局转折
- GPT-4o免费开放策略转变标志竞争从技术转向生态，原生多模态统一处理成为新标准
- o1推理模型引入System 2思考，从快速反应到深度推理的范式转变
- 中国在MoE架构、中文理解、垂直应用上建立独特优势，中美并驾齐驱格局形成

**参考文献** (Chapter References):
- DeepSeek. (2024). DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model. Technical Report.
- Google DeepMind. (2024). Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. Technical Report.
- OpenAI. (2024). Sora: Creating video from text. Technical Report.
- Anthropic. (2024). The Claude 3 Model Family: Opus, Sonnet, Haiku. Technical Report.
- OpenAI. (2024). GPT-4o System Card. Technical Report.
- Meta AI. (2024). The Llama 3 Herd of Models. Technical Report.
- OpenAI. (2024). Learning to Reason with LLMs (o1 System Card). Technical Report.
- 阿里云. (2024). 通义千问Qwen1.5技术报告.
- 智谱AI. (2024). GLM-4技术文档.
- TechCrunch, The Verge, MIT Technology Review等科技媒体2024年AI发展报道
